{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9f6be7",
   "metadata": {},
   "source": [
    "# CSME2 Bonus Point Assignment II Part 3\n",
    "<div style=\"text-align: right;font-size: 0.8em\">Document Version 2.1.0, released 2022-02-09</div>\n",
    "For task instructions, refer to the assignment PDF.\n",
    "\n",
    "* The parts of the code you are to implement are indicated via `# FILL HERE` comments.\n",
    "* Some cells create export file in the `output/` folder. _Include whole `output/` folder in your submission_.\n",
    "* Make sure you restart the notebook's kernel and run everything in one go before submission\n",
    "* DO NOT CLEAR THE OUTPUT of the notebook you are submitting.\n",
    "\n",
    "_v2.1.0 Fix imports and set default dtype to float_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c15c1814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/.conda/envs/Info2/lib/python3.9/site-packages/torch/__init__.py:471: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n",
      "  warnings.warn((\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path('.')\n",
    "DATA = ROOT / 'data'\n",
    "EXAMPLE_IMAGE = DATA / 'example_image.png'\n",
    "OUTPUT = ROOT / 'output'\n",
    "\n",
    "OUTPUT.mkdir(exist_ok=True)\n",
    "\n",
    "# Enable reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.set_deterministic(True)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8edc226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FILL HERE #####\n",
    "#### Question 3.2 ###\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "train_ds = ImageFolder(DATA / 'train',transform=transform)\n",
    "val_ds = ImageFolder(DATA / 'test',transform=transform)\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10265d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SimpLeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ##### FILL HERE #####\n",
    "        #### Question 3.3 ###\n",
    "        #####################\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(3,16,3,stride=1,padding=1)\n",
    "        self.pool =  torch.nn.MaxPool2d(2,stride=2)\n",
    "        self.fc1 =  torch.nn.Linear(16*150*150,16)\n",
    "        self.fc2 = torch.nn.Linear(16,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ##### FILL HERE #####\n",
    "        #### Question 3.3 ###\n",
    "        #####################\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854c268",
   "metadata": {},
   "source": [
    "_v2.1.0: fix typos, cast tensors to float and reshape outputs to labels_\n",
    "\n",
    "_v2.1.1: add indication that labels should be transformed to either 0. or 1., so the loss function can understand them_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cfb6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, batch_size, epochs, learning_rate, qname):\n",
    "    n_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    print(f'Number of trainable parameters: {n_params}')\n",
    "    \n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    \n",
    "    ##### FILL HERE #####\n",
    "    #### Question 3.4 ###\n",
    "    # Create dataloader from train_ds\n",
    "    dataloader = DataLoader(train_ds,batch_size=batch_size,shuffle=True)\n",
    "    dataloader_val = DataLoader(val_ds,batch_size=batch_size,shuffle=True)\n",
    "    #####################\n",
    "    \n",
    "    with tqdm(range(epochs)) as pbar:\n",
    "        for epoch in pbar:  # loop over the dataset multiple times\n",
    "            running_loss = 0.0\n",
    "            for i, (inputs, labels) in enumerate(dataloader):\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                ##### FILL HERE #####\n",
    "                #### Question 3.4 ###\n",
    "                # Transform the class labels (in variable `labels`)\n",
    "                # to be either 0. or 1, so the loss function\n",
    "                # can understand them\n",
    "                val_loss = 0.\n",
    "                for (inputs_val,labels_val) in dataloader_val:\n",
    "                    outputs_val = net(inputs_val)\n",
    "                    loss_val = criterion(outputs_val, labels_val.unsqueeze(dim=1).float())\n",
    "                    val_loss += loss_val.item()*inputs_val.shape[0]\n",
    "\n",
    "\n",
    "                #####################\n",
    "                \n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs.to(torch.float32))\n",
    "                outputs = outputs.reshape(labels.shape)\n",
    "                loss = criterion(outputs, labels.to(torch.float32))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # training curve\n",
    "                running_loss += loss.item() * inputs.shape[0]\n",
    "            \n",
    "            ##### FILL HERE #####\n",
    "            #### Question 3.4 ###\n",
    "            # Compute Validation loss\n",
    "            val_loss = 0.\n",
    "            for i, (inputs_val,labels_val) in enumerate(dataloader_val):\n",
    "                outputs_val = net(inputs_val)\n",
    "                loss_val = criterion(outputs_val, labels_val.unsqueeze(dim=1).float())\n",
    "                val_loss += loss_val.item()*inputs_val.shape[0]\n",
    "            #####################\n",
    "            \n",
    "            losses.append([running_loss, val_loss])\n",
    "            pbar.set_description(f\"Loss {losses[-1][0]:.02f}/{losses[-1][1]:.02f}\")\n",
    "    \n",
    "    # Save outputs\n",
    "    with open(str(OUTPUT / f'{qname}.pt'), \"wb\") as f:\n",
    "        torch.save(net, f)\n",
    "    losses = np.array(losses)\n",
    "    plt.plot(np.arange(len(losses)), losses[:, 0], label=\"train\")\n",
    "    plt.plot(np.arange(len(losses)), losses[:, 1], label=\"validation\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(OUTPUT / f'{qname}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "624bee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpLeNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=360000, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 5760481\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c20cd481c24443e68925f26714591f76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/93/1522g0bj4wqfpzvdvlm_wybr0000gn/T/ipykernel_9192/1069371428.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mqname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'question_3-4'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mqname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;31m#####################\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/93/1522g0bj4wqfpzvdvlm_wybr0000gn/T/ipykernel_9192/4008761139.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(net, batch_size, epochs, learning_rate, qname)\u001B[0m\n\u001B[1;32m     28\u001B[0m                 \u001B[0mval_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minputs_val\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlabels_val\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdataloader_val\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m                     \u001B[0moutputs_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs_val\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m                     \u001B[0mloss_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels_val\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m                     \u001B[0mval_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mloss_val\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minputs_val\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/Info2/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/93/1522g0bj4wqfpzvdvlm_wybr0000gn/T/ipykernel_9192/2394711692.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0;31m#### Question 3.3 ###\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0;31m#####################\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/Info2/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/Info2/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 443\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/Info2/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    437\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[0;32m--> 439\u001B[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0m\u001B[1;32m    440\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "##### RUN HERE #####\n",
    "#### Question 3.4 ###\n",
    "net = SimpLeNet()\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "learning_rate = 0.1\n",
    "qname = 'question_3-4'\n",
    "print(net)\n",
    "train(net, batch_size, epochs, learning_rate, qname)\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c24b7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ##### FILL HERE #####\n",
    "        #### Question 3.5 ###\n",
    "        #####################\n",
    "        self.conv1 = torch.nn.Conv2d(3,16,3,stride=1,padding=1)\n",
    "        self.pool =  torch.nn.MaxPool2d(6,stride=6)\n",
    "        self.fc1 =  torch.nn.Linear(16*50*50,8)\n",
    "        self.fc2 = torch.nn.Linear(8,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##### FILL HERE #####\n",
    "        #### Question 3.5 ###\n",
    "        #####################\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c20d8",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##### RUN HERE #####\n",
    "#### Question 3.5 ###\n",
    "convnet = ConvNet()\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "qname = 'question_3-5'\n",
    "print(convnet)\n",
    "train(convnet, batch_size, epochs, learning_rate, qname)\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}